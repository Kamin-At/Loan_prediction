{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Dropout, Input, Activation, Flatten, LeakyReLU, Add, GaussianNoise\n",
    "from keras.layers import LSTM, Embedding, Conv1D, GlobalAveragePooling1D, ZeroPadding1D, MaxPooling1D, GRU, UpSampling1D\n",
    "from keras.layers import Conv2D, GlobalAveragePooling2D, ZeroPadding2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential, load_model, model_from_json\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.backend import clear_session\n",
    "from keras import regularizers\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import csv\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance = 'cosine'\n",
    "Train = pd.read_csv(f'.\\data\\Train_v5_{Distance}_with_handcrafted_features1_8.csv', index_col = 0)\n",
    "Label = Train['Loan_Status']\n",
    "Train = Train.drop('Loan_Status',axis = 1)\n",
    "Test = pd.read_csv(f'.\\data\\Test_v5_{Distance}_with_handcrafted_features1_8.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Dependents_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Property_Area_Semiurban</th>\n",
       "      <th>Property_Area_Urban</th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.187296</td>\n",
       "      <td>0.649837</td>\n",
       "      <td>0.781759</td>\n",
       "      <td>0.135179</td>\n",
       "      <td>0.066709</td>\n",
       "      <td>0.038910</td>\n",
       "      <td>0.210161</td>\n",
       "      <td>0.712541</td>\n",
       "      <td>0.838762</td>\n",
       "      <td>0.576547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379479</td>\n",
       "      <td>0.328990</td>\n",
       "      <td>0.233474</td>\n",
       "      <td>0.268284</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.772063</td>\n",
       "      <td>0.227937</td>\n",
       "      <td>0.097815</td>\n",
       "      <td>0.031164</td>\n",
       "      <td>0.051280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.390467</td>\n",
       "      <td>0.477410</td>\n",
       "      <td>0.413389</td>\n",
       "      <td>0.342194</td>\n",
       "      <td>0.075420</td>\n",
       "      <td>0.070229</td>\n",
       "      <td>0.123294</td>\n",
       "      <td>0.135514</td>\n",
       "      <td>0.368050</td>\n",
       "      <td>0.494509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485653</td>\n",
       "      <td>0.470229</td>\n",
       "      <td>0.081756</td>\n",
       "      <td>0.141921</td>\n",
       "      <td>0.055046</td>\n",
       "      <td>0.237441</td>\n",
       "      <td>0.237441</td>\n",
       "      <td>0.084586</td>\n",
       "      <td>0.056816</td>\n",
       "      <td>0.056457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024669</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.022869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190076</td>\n",
       "      <td>0.170275</td>\n",
       "      <td>0.048649</td>\n",
       "      <td>0.574150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047068</td>\n",
       "      <td>0.028524</td>\n",
       "      <td>0.182857</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236027</td>\n",
       "      <td>0.253516</td>\n",
       "      <td>0.068702</td>\n",
       "      <td>0.798036</td>\n",
       "      <td>0.201964</td>\n",
       "      <td>0.081002</td>\n",
       "      <td>0.023507</td>\n",
       "      <td>0.044823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071543</td>\n",
       "      <td>0.055134</td>\n",
       "      <td>0.242143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276057</td>\n",
       "      <td>0.335329</td>\n",
       "      <td>0.087379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425850</td>\n",
       "      <td>0.105903</td>\n",
       "      <td>0.047346</td>\n",
       "      <td>0.063978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990115</td>\n",
       "      <td>0.828875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Gender     Married   Education  Self_Employed  ApplicantIncome  \\\n",
       "count  614.000000  614.000000  614.000000     614.000000       614.000000   \n",
       "mean     0.187296    0.649837    0.781759       0.135179         0.066709   \n",
       "std      0.390467    0.477410    0.413389       0.342194         0.075420   \n",
       "min      0.000000    0.000000    0.000000       0.000000         0.001852   \n",
       "25%      0.000000    0.000000    1.000000       0.000000         0.035525   \n",
       "50%      0.000000    1.000000    1.000000       0.000000         0.047068   \n",
       "75%      0.000000    1.000000    1.000000       0.000000         0.071543   \n",
       "max      1.000000    1.000000    1.000000       1.000000         1.000000   \n",
       "\n",
       "       CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "count         614.000000  614.000000        614.000000      614.000000   \n",
       "mean            0.038910    0.210161          0.712541        0.838762   \n",
       "std             0.070229    0.123294          0.135514        0.368050   \n",
       "min             0.000000    0.012857          0.025000        0.000000   \n",
       "25%             0.000000    0.142857          0.750000        1.000000   \n",
       "50%             0.028524    0.182857          0.750000        1.000000   \n",
       "75%             0.055134    0.242143          0.750000        1.000000   \n",
       "max             1.000000    1.000000          1.000000        1.000000   \n",
       "\n",
       "       Dependents_0  ...  Property_Area_Semiurban  Property_Area_Urban  \\\n",
       "count    614.000000  ...               614.000000           614.000000   \n",
       "mean       0.576547  ...                 0.379479             0.328990   \n",
       "std        0.494509  ...                 0.485653             0.470229   \n",
       "min        0.000000  ...                 0.000000             0.000000   \n",
       "25%        0.000000  ...                 0.000000             0.000000   \n",
       "50%        1.000000  ...                 0.000000             0.000000   \n",
       "75%        1.000000  ...                 1.000000             1.000000   \n",
       "max        1.000000  ...                 1.000000             1.000000   \n",
       "\n",
       "         feature0    feature1    feature2    feature3    feature4    feature5  \\\n",
       "count  614.000000  614.000000  614.000000  614.000000  614.000000  614.000000   \n",
       "mean     0.233474    0.268284    0.074998    0.772063    0.227937    0.097815   \n",
       "std      0.081756    0.141921    0.055046    0.237441    0.237441    0.084586   \n",
       "min      0.024669    0.006424    0.002703    0.009885    0.000000    0.002778   \n",
       "25%      0.190076    0.170275    0.048649    0.574150    0.000000    0.058607   \n",
       "50%      0.236027    0.253516    0.068702    0.798036    0.201964    0.081002   \n",
       "75%      0.276057    0.335329    0.087379    1.000000    0.425850    0.105903   \n",
       "max      0.808736    1.000000    1.000000    1.000000    0.990115    0.828875   \n",
       "\n",
       "         feature6    feature7  \n",
       "count  614.000000  614.000000  \n",
       "mean     0.031164    0.051280  \n",
       "std      0.056816    0.056457  \n",
       "min      0.000000   -0.022869  \n",
       "25%      0.000000    0.024255  \n",
       "50%      0.023507    0.044823  \n",
       "75%      0.047346    0.063978  \n",
       "max      1.000000    1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Train.shape)\n",
    "Train.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(367, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Dependents_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Property_Area_Semiurban</th>\n",
       "      <th>Property_Area_Urban</th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.196185</td>\n",
       "      <td>0.634877</td>\n",
       "      <td>0.771117</td>\n",
       "      <td>0.103542</td>\n",
       "      <td>0.059328</td>\n",
       "      <td>0.037670</td>\n",
       "      <td>0.195232</td>\n",
       "      <td>0.712511</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>0.561308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316076</td>\n",
       "      <td>0.381471</td>\n",
       "      <td>0.238748</td>\n",
       "      <td>0.273298</td>\n",
       "      <td>0.073583</td>\n",
       "      <td>0.763742</td>\n",
       "      <td>0.236258</td>\n",
       "      <td>0.092871</td>\n",
       "      <td>0.032577</td>\n",
       "      <td>0.049828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.397652</td>\n",
       "      <td>0.482122</td>\n",
       "      <td>0.420687</td>\n",
       "      <td>0.305082</td>\n",
       "      <td>0.060626</td>\n",
       "      <td>0.056021</td>\n",
       "      <td>0.088366</td>\n",
       "      <td>0.138158</td>\n",
       "      <td>0.372780</td>\n",
       "      <td>0.496905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465578</td>\n",
       "      <td>0.486411</td>\n",
       "      <td>0.091139</td>\n",
       "      <td>0.129595</td>\n",
       "      <td>0.034669</td>\n",
       "      <td>0.242520</td>\n",
       "      <td>0.242520</td>\n",
       "      <td>0.074385</td>\n",
       "      <td>0.050850</td>\n",
       "      <td>0.035558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018624</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.024458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143571</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190907</td>\n",
       "      <td>0.190703</td>\n",
       "      <td>0.051136</td>\n",
       "      <td>0.552370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046741</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237313</td>\n",
       "      <td>0.262612</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.796425</td>\n",
       "      <td>0.203575</td>\n",
       "      <td>0.080469</td>\n",
       "      <td>0.019730</td>\n",
       "      <td>0.045093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062469</td>\n",
       "      <td>0.058332</td>\n",
       "      <td>0.225714</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280793</td>\n",
       "      <td>0.339534</td>\n",
       "      <td>0.086126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447630</td>\n",
       "      <td>0.104162</td>\n",
       "      <td>0.047535</td>\n",
       "      <td>0.062694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895420</td>\n",
       "      <td>0.575995</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849985</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431321</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Gender     Married   Education  Self_Employed  ApplicantIncome  \\\n",
       "count  367.000000  367.000000  367.000000     367.000000       367.000000   \n",
       "mean     0.196185    0.634877    0.771117       0.103542         0.059328   \n",
       "std      0.397652    0.482122    0.420687       0.305082         0.060626   \n",
       "min      0.000000    0.000000    0.000000       0.000000         0.000000   \n",
       "25%      0.000000    0.000000    1.000000       0.000000         0.035358   \n",
       "50%      0.000000    1.000000    1.000000       0.000000         0.046741   \n",
       "75%      0.000000    1.000000    1.000000       0.000000         0.062469   \n",
       "max      1.000000    1.000000    1.000000       1.000000         0.895420   \n",
       "\n",
       "       CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "count         367.000000  367.000000        367.000000      367.000000   \n",
       "mean            0.037670    0.195232          0.712511        0.833787   \n",
       "std             0.056021    0.088366          0.138158        0.372780   \n",
       "min             0.000000    0.040000          0.012500        0.000000   \n",
       "25%             0.000000    0.143571          0.750000        1.000000   \n",
       "50%             0.024600    0.178571          0.750000        1.000000   \n",
       "75%             0.058332    0.225714          0.750000        1.000000   \n",
       "max             0.575995    0.785714          1.000000        1.000000   \n",
       "\n",
       "       Dependents_0  ...  Property_Area_Semiurban  Property_Area_Urban  \\\n",
       "count    367.000000  ...               367.000000           367.000000   \n",
       "mean       0.561308  ...                 0.316076             0.381471   \n",
       "std        0.496905  ...                 0.465578             0.486411   \n",
       "min        0.000000  ...                 0.000000             0.000000   \n",
       "25%        0.000000  ...                 0.000000             0.000000   \n",
       "50%        1.000000  ...                 0.000000             0.000000   \n",
       "75%        1.000000  ...                 1.000000             1.000000   \n",
       "max        1.000000  ...                 1.000000             1.000000   \n",
       "\n",
       "         feature0    feature1    feature2    feature3    feature4    feature5  \\\n",
       "count  367.000000  367.000000  367.000000  367.000000  367.000000  367.000000   \n",
       "mean     0.238748    0.273298    0.073583    0.763742    0.236258    0.092871   \n",
       "std      0.091139    0.129595    0.034669    0.242520    0.242520    0.074385   \n",
       "min      0.018624    0.004414    0.001154    0.000000    0.000000    0.000000   \n",
       "25%      0.190907    0.190703    0.051136    0.552370    0.000000    0.057193   \n",
       "50%      0.237313    0.262612    0.068966    0.796425    0.203575    0.080469   \n",
       "75%      0.280793    0.339534    0.086126    1.000000    0.447630    0.104162   \n",
       "max      1.000000    0.849985    0.257143    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature6    feature7  \n",
       "count  367.000000  367.000000  \n",
       "mean     0.032577    0.049828  \n",
       "std      0.050850    0.035558  \n",
       "min      0.000000   -0.024458  \n",
       "25%      0.000000    0.026807  \n",
       "50%      0.019730    0.045093  \n",
       "75%      0.047535    0.062694  \n",
       "max      0.431321    0.238095  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Test.shape)\n",
    "Test.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Dependents_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Property_Area_Semiurban</th>\n",
       "      <th>Property_Area_Urban</th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.190622</td>\n",
       "      <td>0.644241</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.123344</td>\n",
       "      <td>0.063948</td>\n",
       "      <td>0.038446</td>\n",
       "      <td>0.204576</td>\n",
       "      <td>0.712530</td>\n",
       "      <td>0.836901</td>\n",
       "      <td>0.570846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355759</td>\n",
       "      <td>0.348624</td>\n",
       "      <td>0.235447</td>\n",
       "      <td>0.270159</td>\n",
       "      <td>0.074469</td>\n",
       "      <td>0.768950</td>\n",
       "      <td>0.231050</td>\n",
       "      <td>0.095965</td>\n",
       "      <td>0.031692</td>\n",
       "      <td>0.050737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.392992</td>\n",
       "      <td>0.478987</td>\n",
       "      <td>0.415952</td>\n",
       "      <td>0.328999</td>\n",
       "      <td>0.070310</td>\n",
       "      <td>0.065250</td>\n",
       "      <td>0.111701</td>\n",
       "      <td>0.136439</td>\n",
       "      <td>0.369644</td>\n",
       "      <td>0.495208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478987</td>\n",
       "      <td>0.476778</td>\n",
       "      <td>0.085379</td>\n",
       "      <td>0.137394</td>\n",
       "      <td>0.048422</td>\n",
       "      <td>0.239264</td>\n",
       "      <td>0.239264</td>\n",
       "      <td>0.080917</td>\n",
       "      <td>0.054638</td>\n",
       "      <td>0.049663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018624</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.024458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190824</td>\n",
       "      <td>0.175106</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.568522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046914</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>0.181429</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237154</td>\n",
       "      <td>0.258099</td>\n",
       "      <td>0.068702</td>\n",
       "      <td>0.796607</td>\n",
       "      <td>0.203393</td>\n",
       "      <td>0.080825</td>\n",
       "      <td>0.022206</td>\n",
       "      <td>0.044823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068099</td>\n",
       "      <td>0.056760</td>\n",
       "      <td>0.231429</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277644</td>\n",
       "      <td>0.336837</td>\n",
       "      <td>0.086538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431478</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.047413</td>\n",
       "      <td>0.063116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Gender     Married   Education  Self_Employed  ApplicantIncome  \\\n",
       "count  981.000000  981.000000  981.000000     981.000000       981.000000   \n",
       "mean     0.190622    0.644241    0.777778       0.123344         0.063948   \n",
       "std      0.392992    0.478987    0.415952       0.328999         0.070310   \n",
       "min      0.000000    0.000000    0.000000       0.000000         0.000000   \n",
       "25%      0.000000    0.000000    1.000000       0.000000         0.035494   \n",
       "50%      0.000000    1.000000    1.000000       0.000000         0.046914   \n",
       "75%      0.000000    1.000000    1.000000       0.000000         0.068099   \n",
       "max      1.000000    1.000000    1.000000       1.000000         1.000000   \n",
       "\n",
       "       CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "count         981.000000  981.000000        981.000000      981.000000   \n",
       "mean            0.038446    0.204576          0.712530        0.836901   \n",
       "std             0.065250    0.111701          0.136439        0.369644   \n",
       "min             0.000000    0.012857          0.012500        0.000000   \n",
       "25%             0.000000    0.142857          0.750000        1.000000   \n",
       "50%             0.026640    0.181429          0.750000        1.000000   \n",
       "75%             0.056760    0.231429          0.750000        1.000000   \n",
       "max             1.000000    1.000000          1.000000        1.000000   \n",
       "\n",
       "       Dependents_0  ...  Property_Area_Semiurban  Property_Area_Urban  \\\n",
       "count    981.000000  ...               981.000000           981.000000   \n",
       "mean       0.570846  ...                 0.355759             0.348624   \n",
       "std        0.495208  ...                 0.478987             0.476778   \n",
       "min        0.000000  ...                 0.000000             0.000000   \n",
       "25%        0.000000  ...                 0.000000             0.000000   \n",
       "50%        1.000000  ...                 0.000000             0.000000   \n",
       "75%        1.000000  ...                 1.000000             1.000000   \n",
       "max        1.000000  ...                 1.000000             1.000000   \n",
       "\n",
       "         feature0    feature1    feature2    feature3    feature4    feature5  \\\n",
       "count  981.000000  981.000000  981.000000  981.000000  981.000000  981.000000   \n",
       "mean     0.235447    0.270159    0.074469    0.768950    0.231050    0.095965   \n",
       "std      0.085379    0.137394    0.048422    0.239264    0.239264    0.080917   \n",
       "min      0.018624    0.004414    0.001154    0.000000    0.000000    0.000000   \n",
       "25%      0.190824    0.175106    0.050000    0.568522    0.000000    0.057944   \n",
       "50%      0.237154    0.258099    0.068702    0.796607    0.203393    0.080825   \n",
       "75%      0.277644    0.336837    0.086538    1.000000    0.431478    0.105000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature6    feature7  \n",
       "count  981.000000  981.000000  \n",
       "mean     0.031692    0.050737  \n",
       "std      0.054638    0.049663  \n",
       "min      0.000000   -0.024458  \n",
       "25%      0.000000    0.025641  \n",
       "50%      0.022206    0.044823  \n",
       "75%      0.047413    0.063116  \n",
       "max      1.000000    1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = pd.concat([Train, Test])\n",
    "Data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=0.8, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.8)\n",
    "pca.fit(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pca.transform(Train.values)\n",
    "Test = pca.transform(Test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\Admin\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67116296 0.71940714 0.6745115  0.80120397 0.5288806  0.56013334\n",
      " 0.6800602  0.30074677 0.6930413  0.8127038  0.61675334 0.46837237\n",
      " 0.695681   0.47941378 0.71883994 0.6655173  0.61971056 0.7449505\n",
      " 0.6891653  0.7440988  0.81759435 0.6116314  0.68058616 0.7267974\n",
      " 0.6690069  0.4351268  0.74982864 0.56067663 0.817944   0.69348097\n",
      " 0.6469184  0.6830731  0.6803191  0.7964591  0.64436203 0.33708164\n",
      " 0.59531933 0.7286272  0.6826688  0.7640293  0.6585181  0.71084225\n",
      " 0.7461532  0.58455086 0.62834895 0.66855913 0.70433825 0.7991764\n",
      " 0.68834466 0.65661985 0.62607443 0.7709946  0.666314   0.7500958\n",
      " 0.5797586  0.31817052 0.68537015 0.7493428  0.4970763  0.6262102\n",
      " 0.77669597 0.69656336 0.5630683  0.50327593 0.71163154 0.7646271\n",
      " 0.48779044 0.33156613 0.61301404 0.6726358  0.7657935  0.6323201\n",
      " 0.66735786 0.4759737  0.7683204  0.6929798  0.6746993  0.68189245\n",
      " 0.67333025 0.6487697  0.53661424 0.69264835 0.43663996 0.6603832\n",
      " 0.53425133 0.6866492  0.75020784 0.7657935  0.72000533 0.5244026\n",
      " 0.6820899  0.6620723  0.60052663 0.7312833  0.5578373  0.70453054\n",
      " 0.6050082  0.78240323 0.61419207 0.6842259  0.67966235 0.41737056\n",
      " 0.72033614 0.6336465  0.8233148  0.5187067  0.6644824  0.6749991\n",
      " 0.6800015  0.6666558  0.69780344 0.724343   0.6323507  0.7646271\n",
      " 0.6929889  0.70391554 0.3616385  0.40404034 0.37904003 0.37786433\n",
      " 0.62400955 0.5535943  0.7198916  0.6939314  0.51035726 0.71883994\n",
      " 0.5289559  0.6734059  0.65535754 0.658533   0.7278092  0.46478185\n",
      " 0.58638823 0.7122426  0.653624   0.7106034  0.67966235 0.44093478\n",
      " 0.76856136 0.73740077 0.5087803  0.8288724  0.48643813 0.6803058\n",
      " 0.6456421  0.6650225  0.71084696 0.43097857 0.77155113 0.69782525\n",
      " 0.65830207 0.7256825  0.67966235 0.5608932  0.5307738  0.73693544\n",
      " 0.6155629  0.67252773 0.5831021  0.6163265  0.7030559  0.55766124\n",
      " 0.6826688  0.5345467  0.64160556 0.31680104 0.2964334  0.8076994\n",
      " 0.59868383 0.45043042 0.69212514 0.68537015 0.6749991  0.6024502\n",
      " 0.510521   0.73503107 0.5656453  0.55243874 0.6749991  0.6650225\n",
      " 0.6279419  0.6940101  0.7109138  0.6646711  0.69656336 0.6848434\n",
      " 0.7391654  0.6864846  0.6381699  0.61848253 0.65153176 0.62706673\n",
      " 0.45998335 0.552014   0.67771155 0.6826688  0.51082367 0.7149039\n",
      " 0.5221614  0.76907724 0.49121493 0.64546204 0.6847053  0.81560105\n",
      " 0.7173683  0.83220166 0.61369205 0.748473   0.6010904  0.5297114\n",
      " 0.47792324 0.46091208 0.6619487  0.6749991  0.73066014 0.5850516\n",
      " 0.794437   0.55729425 0.72367555 0.63148093 0.8475635  0.67626625\n",
      " 0.54317075 0.67836267 0.5328066  0.6234273  0.6713009  0.77082616\n",
      " 0.7681262  0.49525526 0.6307987  0.7962482  0.6840735  0.74647516\n",
      " 0.8138826  0.557915   0.64954937 0.55391455 0.78416973 0.5263157\n",
      " 0.66681075 0.5912794  0.70329434 0.4998587  0.66333157 0.64700526\n",
      " 0.73661745 0.6726257  0.5990331  0.6643945  0.28579122 0.67786676\n",
      " 0.7471249  0.7063396  0.7009208  0.29969564 0.568898   0.6234914\n",
      " 0.73103565 0.3758626  0.7091822  0.71190804 0.56487066 0.64994264\n",
      " 0.42545515 0.78616875 0.42760065 0.7154196  0.61087257 0.58303726\n",
      " 0.45334193 0.7481253  0.66733265 0.58263576 0.5375028  0.7463943\n",
      " 0.6739374  0.6689665  0.31267545 0.66818154 0.8238008  0.69133\n",
      " 0.58865047 0.6353486  0.5633856  0.71886116 0.40476277 0.6006792\n",
      " 0.7023054  0.668424   0.6340077  0.82243514 0.55925924 0.63796574\n",
      " 0.5343593  0.5928763  0.71185815 0.49992472 0.7630397  0.67966235\n",
      " 0.56060493 0.5052092  0.6502112  0.4720484  0.76674926 0.4105003\n",
      " 0.6040179  0.6968491  0.6322504  0.75286114 0.69782525 0.48825747\n",
      " 0.8037922  0.67966235 0.6852763  0.66702086 0.6749991  0.4042659\n",
      " 0.68075097 0.8076994  0.6513852  0.48466787 0.63711995 0.7660062\n",
      " 0.57339156 0.7362146  0.56794584 0.71948355 0.6502112  0.759815\n",
      " 0.6749991  0.72006464 0.63754725 0.69780344 0.7709085  0.67905277\n",
      " 0.68422717 0.67512286 0.5511215  0.38073593 0.7249993  0.6922145\n",
      " 0.5413638  0.56060493 0.65815663 0.7003207  0.50966066 0.4931496\n",
      " 0.71265894 0.4671345  0.68070257 0.40095112 0.71197295 0.71416366\n",
      " 0.50316906 0.6835601  0.68977386 0.71453315 0.4026289  0.6933612\n",
      " 0.6870307  0.77947    0.72295535 0.689169   0.746862   0.67252773\n",
      " 0.6479807 ]\n"
     ]
    }
   ],
   "source": [
    "num_tree = 16\n",
    "max_depth = 5\n",
    "col_sample_by_tree = 0.3\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:logistic', colsample_bytree = col_sample_by_tree, learning_rate = 0.1,\\\n",
    "                          max_depth = max_depth, alpha = 10, n_estimators = num_tree)\n",
    "xg_reg.fit(Train,Label)\n",
    "OUT = xg_reg.predict(Test)\n",
    "print(OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.55\n",
    "OUT2 = []\n",
    "for i in range(len(OUT)):\n",
    "    if OUT[i] > threshold:\n",
    "        OUT2.append('1')\n",
    "    else:\n",
    "        OUT2.append('0')\n",
    "print(OUT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS = pd.DataFrame({'Loan_ID':Test.index, 'Loan_Status':OUT2}).replace({'1':'Y', '0':'N'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS.to_csv('.\\data\\XG_cos_th_'+str(threshold)+'_NT_'+str(num_tree) +'_max_depth_' + str(max_depth)+ \\\n",
    "           '_sample_cols_' + str(col_sample_by_tree) +'_V6.csv',index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tpng'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_startupinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    730\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1016\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c9fec608aa85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxg_reg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_trees\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'figure.figsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\xgboost\\plotting.py\u001b[0m in \u001b[0;36mplot_tree\u001b[1;34m(booster, fmap, num_trees, rankdir, ax, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(engine, format, data, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \"\"\"\n\u001b[0;32m    205\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tpng'], make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_tree(xg_reg,num_trees=0)\n",
    "plt.rcParams['figure.figsize'] = [50, 10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "367\n"
     ]
    }
   ],
   "source": [
    "Gamma = 0.1\n",
    "C = 1\n",
    "clf = SVC(gamma= Gamma, C= C, class_weight='balanced')\n",
    "clf.fit(Train.values, Label.values) \n",
    "OUT = clf.predict(Test.values)\n",
    "print(OUT)\n",
    "print(len(OUT))\n",
    "OUT = [str(i) for i in OUT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS = pd.DataFrame({'Loan_ID':Test.index, 'Loan_Status':OUT}).replace({'1':'Y', '0':'N'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS.to_csv(f'.\\data\\SVM_{Distance}_C_'+str(C)+'_Gamma_'+str(Gamma)+'_V5.csv',index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LP001015</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LP001022</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LP001031</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LP001035</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LP001051</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362</td>\n",
       "      <td>LP002971</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>LP002975</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>LP002980</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>LP002986</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>LP002989</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID Loan_Status\n",
       "0    LP001015           Y\n",
       "1    LP001022           Y\n",
       "2    LP001031           Y\n",
       "3    LP001035           Y\n",
       "4    LP001051           Y\n",
       "..        ...         ...\n",
       "362  LP002971           N\n",
       "363  LP002975           Y\n",
       "364  LP002980           Y\n",
       "365  LP002986           Y\n",
       "366  LP002989           Y\n",
       "\n",
       "[367 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "367\n"
     ]
    }
   ],
   "source": [
    "L = 5\n",
    "hidden = 1\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(L,hidden),max_iter=1000, random_state=1,learning_rate = 'adaptive')\n",
    "clf.fit(Train.values, Label.values) \n",
    "OUT = clf.predict(Test.values)\n",
    "print(OUT)\n",
    "print(len(OUT))\n",
    "OUT = [str(i) for i in OUT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS = pd.DataFrame({'Loan_ID':Test.index, 'Loan_Status':OUT}).replace({'1':'Y', '0':'N'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS.to_csv('.\\data\\MLP_L_'+str(L)+ '_hidden_'+ str(hidden) +'_V2.csv',index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6872964169381107, 0.3127035830618892]\n"
     ]
    }
   ],
   "source": [
    "#compute imbalancing\n",
    "SUM_1 = np.sum(Label)\n",
    "class_weights = [SUM_1/Label.shape[0], (Label.shape[0]-SUM_1)/Label.shape[0]]\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.59895833 0.72748815]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(Label.values),Label.values)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 491 samples, validate on 123 samples\n",
      "Epoch 1/1000\n",
      " - 1s - loss: 0.6205 - acc: 0.6945 - val_loss: 0.6202 - val_acc: 0.6829\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 0.6053 - acc: 0.6884 - val_loss: 0.6120 - val_acc: 0.6829\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 0.5939 - acc: 0.6884 - val_loss: 0.6068 - val_acc: 0.6829\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 0.5877 - acc: 0.6884 - val_loss: 0.6027 - val_acc: 0.6829\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 0.5829 - acc: 0.6884 - val_loss: 0.5979 - val_acc: 0.6829\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 0.5779 - acc: 0.6884 - val_loss: 0.5920 - val_acc: 0.6829\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 0.5719 - acc: 0.6884 - val_loss: 0.5862 - val_acc: 0.6829\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 0.5673 - acc: 0.6884 - val_loss: 0.5808 - val_acc: 0.6829\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 0.5617 - acc: 0.6884 - val_loss: 0.5773 - val_acc: 0.6829\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 0.5582 - acc: 0.6884 - val_loss: 0.5745 - val_acc: 0.6829\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 0.5546 - acc: 0.6884 - val_loss: 0.5716 - val_acc: 0.6829\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 0.5511 - acc: 0.6884 - val_loss: 0.5693 - val_acc: 0.6829\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 0.5475 - acc: 0.6864 - val_loss: 0.5672 - val_acc: 0.6829\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 0.5438 - acc: 0.7149 - val_loss: 0.5655 - val_acc: 0.6829\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 0.5403 - acc: 0.7271 - val_loss: 0.5640 - val_acc: 0.6992\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 0.5375 - acc: 0.7189 - val_loss: 0.5620 - val_acc: 0.7236\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 0.5350 - acc: 0.7169 - val_loss: 0.5599 - val_acc: 0.7236\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 0.5334 - acc: 0.7352 - val_loss: 0.5577 - val_acc: 0.7317\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 0.5308 - acc: 0.7454 - val_loss: 0.5550 - val_acc: 0.7480\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 0.5289 - acc: 0.7454 - val_loss: 0.5525 - val_acc: 0.7398\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 0.5267 - acc: 0.7475 - val_loss: 0.5499 - val_acc: 0.7480\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 0.5251 - acc: 0.7556 - val_loss: 0.5480 - val_acc: 0.7398\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 0.5235 - acc: 0.7617 - val_loss: 0.5459 - val_acc: 0.7561\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 0.5219 - acc: 0.7637 - val_loss: 0.5438 - val_acc: 0.7561\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 0.5208 - acc: 0.7597 - val_loss: 0.5423 - val_acc: 0.7642\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 0.5189 - acc: 0.7658 - val_loss: 0.5404 - val_acc: 0.7724\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 0.5177 - acc: 0.7699 - val_loss: 0.5386 - val_acc: 0.7724\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 0.5160 - acc: 0.7699 - val_loss: 0.5365 - val_acc: 0.7724\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 0.5148 - acc: 0.7699 - val_loss: 0.5340 - val_acc: 0.7805\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 0.5133 - acc: 0.7739 - val_loss: 0.5323 - val_acc: 0.7805\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 0.5120 - acc: 0.7678 - val_loss: 0.5307 - val_acc: 0.7805\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 0.5105 - acc: 0.7739 - val_loss: 0.5292 - val_acc: 0.7805\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 0.5091 - acc: 0.7780 - val_loss: 0.5281 - val_acc: 0.7886\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 0.5077 - acc: 0.7780 - val_loss: 0.5262 - val_acc: 0.7967\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 0.5060 - acc: 0.7821 - val_loss: 0.5245 - val_acc: 0.7886\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 0.5047 - acc: 0.7821 - val_loss: 0.5227 - val_acc: 0.7886\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 0.5033 - acc: 0.7821 - val_loss: 0.5213 - val_acc: 0.7967\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 0.5021 - acc: 0.7841 - val_loss: 0.5202 - val_acc: 0.7967\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 0.5006 - acc: 0.7841 - val_loss: 0.5196 - val_acc: 0.7967\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 0.4992 - acc: 0.7821 - val_loss: 0.5190 - val_acc: 0.8049\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 0.4981 - acc: 0.7841 - val_loss: 0.5182 - val_acc: 0.8049\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 0.4972 - acc: 0.7862 - val_loss: 0.5176 - val_acc: 0.8130\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 0.4961 - acc: 0.7841 - val_loss: 0.5174 - val_acc: 0.8049\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 0.4946 - acc: 0.7862 - val_loss: 0.5179 - val_acc: 0.8049\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 0.4926 - acc: 0.7882 - val_loss: 0.5179 - val_acc: 0.8049\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 0.4904 - acc: 0.7902 - val_loss: 0.5174 - val_acc: 0.8130\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 0.4884 - acc: 0.7841 - val_loss: 0.5170 - val_acc: 0.7967\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 0.4861 - acc: 0.7984 - val_loss: 0.5168 - val_acc: 0.8049\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 0.4846 - acc: 0.7963 - val_loss: 0.5166 - val_acc: 0.8130\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 0.4833 - acc: 0.7984 - val_loss: 0.5161 - val_acc: 0.8130\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 0.4822 - acc: 0.7984 - val_loss: 0.5153 - val_acc: 0.8130\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 0.4810 - acc: 0.8004 - val_loss: 0.5138 - val_acc: 0.8130\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 0.4796 - acc: 0.8004 - val_loss: 0.5146 - val_acc: 0.8130\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 0.4781 - acc: 0.8004 - val_loss: 0.5150 - val_acc: 0.8130\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 0.4773 - acc: 0.8004 - val_loss: 0.5164 - val_acc: 0.8130\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 0.4761 - acc: 0.8024 - val_loss: 0.5174 - val_acc: 0.8130\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 0.4743 - acc: 0.8024 - val_loss: 0.5193 - val_acc: 0.8049\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 0.4731 - acc: 0.8065 - val_loss: 0.5210 - val_acc: 0.7967\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 0.4720 - acc: 0.8065 - val_loss: 0.5224 - val_acc: 0.7967\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 0.4704 - acc: 0.8065 - val_loss: 0.5245 - val_acc: 0.8049\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 0.4699 - acc: 0.8065 - val_loss: 0.5258 - val_acc: 0.8049\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 0.4687 - acc: 0.8065 - val_loss: 0.5278 - val_acc: 0.8049\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 0.4671 - acc: 0.8065 - val_loss: 0.5305 - val_acc: 0.7967\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 0.4667 - acc: 0.8045 - val_loss: 0.5318 - val_acc: 0.7967\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 0.4652 - acc: 0.8045 - val_loss: 0.5342 - val_acc: 0.7967\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 0.4643 - acc: 0.8045 - val_loss: 0.5361 - val_acc: 0.7967\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 0.4631 - acc: 0.8045 - val_loss: 0.5380 - val_acc: 0.7967\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 0.4618 - acc: 0.8024 - val_loss: 0.5402 - val_acc: 0.7967\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 0.4605 - acc: 0.8024 - val_loss: 0.5429 - val_acc: 0.7967\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 0.4598 - acc: 0.8024 - val_loss: 0.5466 - val_acc: 0.7886\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 0.4586 - acc: 0.8065 - val_loss: 0.5497 - val_acc: 0.7805\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 0.4575 - acc: 0.8024 - val_loss: 0.5506 - val_acc: 0.7805\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 0.4562 - acc: 0.8024 - val_loss: 0.5510 - val_acc: 0.7805\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 0.4555 - acc: 0.8045 - val_loss: 0.5513 - val_acc: 0.7805\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 0.4550 - acc: 0.8045 - val_loss: 0.5528 - val_acc: 0.7805\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 0.4543 - acc: 0.8045 - val_loss: 0.5558 - val_acc: 0.7805\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 0.4533 - acc: 0.8045 - val_loss: 0.5587 - val_acc: 0.7805\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 0.4526 - acc: 0.8065 - val_loss: 0.5623 - val_acc: 0.7805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      " - 0s - loss: 0.4520 - acc: 0.8086 - val_loss: 0.5637 - val_acc: 0.7805\n",
      "Epoch 80/1000\n",
      " - 0s - loss: 0.4513 - acc: 0.8086 - val_loss: 0.5652 - val_acc: 0.7805\n",
      "Epoch 81/1000\n",
      " - 0s - loss: 0.4507 - acc: 0.8086 - val_loss: 0.5660 - val_acc: 0.7805\n",
      "Epoch 82/1000\n",
      " - 0s - loss: 0.4508 - acc: 0.8065 - val_loss: 0.5666 - val_acc: 0.7805\n",
      "Epoch 83/1000\n",
      " - 0s - loss: 0.4497 - acc: 0.8065 - val_loss: 0.5696 - val_acc: 0.7805\n",
      "Epoch 84/1000\n",
      " - 0s - loss: 0.4488 - acc: 0.8065 - val_loss: 0.5718 - val_acc: 0.7805\n",
      "Epoch 85/1000\n",
      " - 0s - loss: 0.4485 - acc: 0.8086 - val_loss: 0.5731 - val_acc: 0.7805\n",
      "Epoch 86/1000\n",
      " - 0s - loss: 0.4480 - acc: 0.8106 - val_loss: 0.5733 - val_acc: 0.7805\n",
      "Epoch 87/1000\n",
      " - 0s - loss: 0.4473 - acc: 0.8106 - val_loss: 0.5720 - val_acc: 0.7805\n",
      "Epoch 88/1000\n",
      " - 0s - loss: 0.4467 - acc: 0.8106 - val_loss: 0.5722 - val_acc: 0.7805\n",
      "Epoch 89/1000\n",
      " - 0s - loss: 0.4461 - acc: 0.8106 - val_loss: 0.5723 - val_acc: 0.7805\n",
      "Epoch 90/1000\n",
      " - 0s - loss: 0.4458 - acc: 0.8106 - val_loss: 0.5730 - val_acc: 0.7805\n",
      "Epoch 91/1000\n",
      " - 0s - loss: 0.4453 - acc: 0.8126 - val_loss: 0.5735 - val_acc: 0.7805\n",
      "Epoch 92/1000\n",
      " - 0s - loss: 0.4446 - acc: 0.8126 - val_loss: 0.5758 - val_acc: 0.7805\n",
      "Epoch 93/1000\n",
      " - 0s - loss: 0.4443 - acc: 0.8126 - val_loss: 0.5767 - val_acc: 0.7805\n",
      "Epoch 94/1000\n",
      " - 0s - loss: 0.4434 - acc: 0.8106 - val_loss: 0.5782 - val_acc: 0.7805\n",
      "Epoch 95/1000\n",
      " - 0s - loss: 0.4431 - acc: 0.8106 - val_loss: 0.5803 - val_acc: 0.7805\n",
      "Epoch 96/1000\n",
      " - 0s - loss: 0.4424 - acc: 0.8106 - val_loss: 0.5806 - val_acc: 0.7805\n",
      "Epoch 97/1000\n",
      " - 0s - loss: 0.4418 - acc: 0.8106 - val_loss: 0.5809 - val_acc: 0.7805\n",
      "Epoch 98/1000\n",
      " - 0s - loss: 0.4412 - acc: 0.8126 - val_loss: 0.5824 - val_acc: 0.7805\n",
      "Epoch 99/1000\n",
      " - 0s - loss: 0.4407 - acc: 0.8086 - val_loss: 0.5840 - val_acc: 0.7805\n",
      "Epoch 100/1000\n",
      " - 0s - loss: 0.4409 - acc: 0.8086 - val_loss: 0.5864 - val_acc: 0.7805\n",
      "Epoch 101/1000\n",
      " - 0s - loss: 0.4402 - acc: 0.8106 - val_loss: 0.5863 - val_acc: 0.7805\n",
      "Epoch 102/1000\n",
      " - 0s - loss: 0.4396 - acc: 0.8126 - val_loss: 0.5847 - val_acc: 0.7805\n",
      "Epoch 103/1000\n",
      " - 0s - loss: 0.4392 - acc: 0.8126 - val_loss: 0.5849 - val_acc: 0.7805\n",
      "Epoch 104/1000\n",
      " - 0s - loss: 0.4390 - acc: 0.8147 - val_loss: 0.5857 - val_acc: 0.7805\n",
      "Epoch 105/1000\n",
      " - 0s - loss: 0.4382 - acc: 0.8126 - val_loss: 0.5877 - val_acc: 0.7805\n",
      "Epoch 106/1000\n",
      " - 0s - loss: 0.4394 - acc: 0.8106 - val_loss: 0.5894 - val_acc: 0.7805\n",
      "Epoch 107/1000\n",
      " - 0s - loss: 0.4383 - acc: 0.8126 - val_loss: 0.5856 - val_acc: 0.7805\n",
      "Epoch 108/1000\n",
      " - 0s - loss: 0.4384 - acc: 0.8126 - val_loss: 0.5808 - val_acc: 0.7724\n",
      "Epoch 109/1000\n",
      " - 0s - loss: 0.4384 - acc: 0.8086 - val_loss: 0.5806 - val_acc: 0.7642\n",
      "Epoch 110/1000\n",
      " - 0s - loss: 0.4377 - acc: 0.8167 - val_loss: 0.5848 - val_acc: 0.7805\n",
      "Epoch 111/1000\n",
      " - 0s - loss: 0.4363 - acc: 0.8106 - val_loss: 0.5875 - val_acc: 0.7805\n",
      "Epoch 112/1000\n",
      " - 0s - loss: 0.4364 - acc: 0.8106 - val_loss: 0.5854 - val_acc: 0.7805\n",
      "Epoch 113/1000\n",
      " - 0s - loss: 0.4357 - acc: 0.8106 - val_loss: 0.5842 - val_acc: 0.7805\n",
      "Epoch 114/1000\n",
      " - 0s - loss: 0.4354 - acc: 0.8106 - val_loss: 0.5817 - val_acc: 0.7805\n",
      "Epoch 115/1000\n",
      " - 0s - loss: 0.4354 - acc: 0.8126 - val_loss: 0.5796 - val_acc: 0.7805\n",
      "Epoch 116/1000\n",
      " - 0s - loss: 0.4349 - acc: 0.8126 - val_loss: 0.5809 - val_acc: 0.7805\n",
      "Epoch 117/1000\n",
      " - 0s - loss: 0.4352 - acc: 0.8126 - val_loss: 0.5832 - val_acc: 0.7805\n",
      "Epoch 118/1000\n",
      " - 0s - loss: 0.4344 - acc: 0.8126 - val_loss: 0.5849 - val_acc: 0.7805\n",
      "Epoch 119/1000\n",
      " - 0s - loss: 0.4345 - acc: 0.8126 - val_loss: 0.5832 - val_acc: 0.7805\n",
      "Epoch 120/1000\n",
      " - 0s - loss: 0.4336 - acc: 0.8147 - val_loss: 0.5842 - val_acc: 0.7805\n",
      "Epoch 121/1000\n",
      " - 0s - loss: 0.4341 - acc: 0.8126 - val_loss: 0.5855 - val_acc: 0.7805\n",
      "Epoch 122/1000\n",
      " - 0s - loss: 0.4329 - acc: 0.8126 - val_loss: 0.5856 - val_acc: 0.7805\n",
      "Epoch 123/1000\n",
      " - 0s - loss: 0.4341 - acc: 0.8126 - val_loss: 0.5878 - val_acc: 0.7805\n",
      "Epoch 124/1000\n",
      " - 0s - loss: 0.4327 - acc: 0.8126 - val_loss: 0.5876 - val_acc: 0.7805\n",
      "Epoch 125/1000\n",
      " - 0s - loss: 0.4322 - acc: 0.8167 - val_loss: 0.5854 - val_acc: 0.7724\n",
      "Epoch 126/1000\n",
      " - 0s - loss: 0.4326 - acc: 0.8167 - val_loss: 0.5868 - val_acc: 0.7805\n",
      "Epoch 127/1000\n",
      " - 0s - loss: 0.4313 - acc: 0.8167 - val_loss: 0.5866 - val_acc: 0.7805\n",
      "Epoch 128/1000\n",
      " - 0s - loss: 0.4307 - acc: 0.8167 - val_loss: 0.5875 - val_acc: 0.7805\n",
      "Epoch 129/1000\n",
      " - 0s - loss: 0.4305 - acc: 0.8167 - val_loss: 0.5881 - val_acc: 0.7805\n",
      "Epoch 130/1000\n",
      " - 0s - loss: 0.4304 - acc: 0.8167 - val_loss: 0.5882 - val_acc: 0.7805\n",
      "Epoch 131/1000\n",
      " - 0s - loss: 0.4303 - acc: 0.8147 - val_loss: 0.5880 - val_acc: 0.7805\n",
      "Epoch 132/1000\n",
      " - 0s - loss: 0.4302 - acc: 0.8147 - val_loss: 0.5884 - val_acc: 0.7805\n",
      "Epoch 133/1000\n",
      " - 0s - loss: 0.4296 - acc: 0.8147 - val_loss: 0.5885 - val_acc: 0.7805\n",
      "Epoch 134/1000\n",
      " - 0s - loss: 0.4298 - acc: 0.8147 - val_loss: 0.5889 - val_acc: 0.7805\n",
      "Epoch 135/1000\n",
      " - 0s - loss: 0.4293 - acc: 0.8167 - val_loss: 0.5873 - val_acc: 0.7805\n",
      "Epoch 136/1000\n",
      " - 0s - loss: 0.4290 - acc: 0.8167 - val_loss: 0.5872 - val_acc: 0.7805\n",
      "Epoch 137/1000\n",
      " - 0s - loss: 0.4302 - acc: 0.8187 - val_loss: 0.5859 - val_acc: 0.7724\n",
      "Epoch 138/1000\n",
      " - 0s - loss: 0.4287 - acc: 0.8187 - val_loss: 0.5881 - val_acc: 0.7805\n",
      "Epoch 139/1000\n",
      " - 0s - loss: 0.4285 - acc: 0.8167 - val_loss: 0.5907 - val_acc: 0.7805\n",
      "Epoch 140/1000\n",
      " - 0s - loss: 0.4288 - acc: 0.8167 - val_loss: 0.5920 - val_acc: 0.7805\n",
      "Epoch 141/1000\n",
      " - 0s - loss: 0.4298 - acc: 0.8167 - val_loss: 0.5891 - val_acc: 0.7805\n",
      "Epoch 142/1000\n",
      " - 0s - loss: 0.4280 - acc: 0.8167 - val_loss: 0.5889 - val_acc: 0.7724\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00142: early stopping\n",
      "[[0.830518  ]\n",
      " [0.7000709 ]\n",
      " [0.87325287]\n",
      " [0.84467626]\n",
      " [0.5397929 ]\n",
      " [0.7878175 ]\n",
      " [0.8609603 ]\n",
      " [0.3935756 ]\n",
      " [0.8957922 ]\n",
      " [0.89111996]\n",
      " [0.53749126]\n",
      " [0.7876762 ]\n",
      " [0.68746877]\n",
      " [0.42322466]\n",
      " [0.8200685 ]\n",
      " [0.55937296]\n",
      " [0.8606403 ]\n",
      " [0.77582705]\n",
      " [0.767181  ]\n",
      " [0.885687  ]\n",
      " [0.66731405]\n",
      " [0.3935756 ]\n",
      " [0.6359892 ]\n",
      " [0.5578515 ]\n",
      " [0.76496583]\n",
      " [0.59410006]\n",
      " [0.876441  ]\n",
      " [0.78183603]\n",
      " [0.9239998 ]\n",
      " [0.5884002 ]\n",
      " [0.88639045]\n",
      " [0.88444823]\n",
      " [0.852118  ]\n",
      " [0.75111103]\n",
      " [0.76654625]\n",
      " [0.3935756 ]\n",
      " [0.86853343]\n",
      " [0.8318963 ]\n",
      " [0.78964114]\n",
      " [0.59309673]\n",
      " [0.80906546]\n",
      " [0.3935756 ]\n",
      " [0.90140283]\n",
      " [0.84753513]\n",
      " [0.39363545]\n",
      " [0.7578986 ]\n",
      " [0.8450279 ]\n",
      " [0.8855088 ]\n",
      " [0.604531  ]\n",
      " [0.8710286 ]\n",
      " [0.6820166 ]\n",
      " [0.7358776 ]\n",
      " [0.7843967 ]\n",
      " [0.88458   ]\n",
      " [0.86766785]\n",
      " [0.3935756 ]\n",
      " [0.7423429 ]\n",
      " [0.95465505]\n",
      " [0.46399122]\n",
      " [0.7932903 ]\n",
      " [0.897207  ]\n",
      " [0.9038408 ]\n",
      " [0.8491189 ]\n",
      " [0.4869698 ]\n",
      " [0.6516558 ]\n",
      " [0.9271643 ]\n",
      " [0.3935756 ]\n",
      " [0.3935756 ]\n",
      " [0.92831916]\n",
      " [0.5345061 ]\n",
      " [0.8234421 ]\n",
      " [0.8270922 ]\n",
      " [0.7164398 ]\n",
      " [0.7967432 ]\n",
      " [0.897725  ]\n",
      " [0.5804812 ]\n",
      " [0.76087606]\n",
      " [0.70214707]\n",
      " [0.7729031 ]\n",
      " [0.62652504]\n",
      " [0.41061044]\n",
      " [0.8640901 ]\n",
      " [0.3935756 ]\n",
      " [0.75542694]\n",
      " [0.3935756 ]\n",
      " [0.8172344 ]\n",
      " [0.7713356 ]\n",
      " [0.8242029 ]\n",
      " [0.8915373 ]\n",
      " [0.6617066 ]\n",
      " [0.79341877]\n",
      " [0.75401115]\n",
      " [0.79988396]\n",
      " [0.93049186]\n",
      " [0.3935756 ]\n",
      " [0.57557017]\n",
      " [0.6571381 ]\n",
      " [0.9265204 ]\n",
      " [0.8413557 ]\n",
      " [0.7890496 ]\n",
      " [0.6086281 ]\n",
      " [0.3935756 ]\n",
      " [0.7572613 ]\n",
      " [0.7620198 ]\n",
      " [0.86777794]\n",
      " [0.90648115]\n",
      " [0.3935756 ]\n",
      " [0.7346242 ]\n",
      " [0.9268267 ]\n",
      " [0.7241564 ]\n",
      " [0.8294398 ]\n",
      " [0.9270593 ]\n",
      " [0.3935756 ]\n",
      " [0.94599384]\n",
      " [0.7244417 ]\n",
      " [0.5123077 ]\n",
      " [0.96922266]\n",
      " [0.39375   ]\n",
      " [0.3935756 ]\n",
      " [0.49724084]\n",
      " [0.63112056]\n",
      " [0.7260455 ]\n",
      " [0.7808469 ]\n",
      " [0.49768728]\n",
      " [0.3935756 ]\n",
      " [0.8257021 ]\n",
      " [0.3935756 ]\n",
      " [0.89193416]\n",
      " [0.6465493 ]\n",
      " [0.84442353]\n",
      " [0.7788784 ]\n",
      " [0.60390204]\n",
      " [0.67949194]\n",
      " [0.41223118]\n",
      " [0.65781456]\n",
      " [0.82590795]\n",
      " [0.83414173]\n",
      " [0.46911743]\n",
      " [0.8463678 ]\n",
      " [0.3935756 ]\n",
      " [0.3935756 ]\n",
      " [0.6084101 ]\n",
      " [0.3935756 ]\n",
      " [0.9569814 ]\n",
      " [0.89597553]\n",
      " [0.4026519 ]\n",
      " [0.7954442 ]\n",
      " [0.3935756 ]\n",
      " [0.83058226]\n",
      " [0.644867  ]\n",
      " [0.57009685]\n",
      " [0.7685858 ]\n",
      " [0.6102226 ]\n",
      " [0.3935756 ]\n",
      " [0.83662766]\n",
      " [0.87541485]\n",
      " [0.9185041 ]\n",
      " [0.718751  ]\n",
      " [0.6671862 ]\n",
      " [0.6135535 ]\n",
      " [0.63004214]\n",
      " [0.3935756 ]\n",
      " [0.64430404]\n",
      " [0.67361957]\n",
      " [0.4260366 ]\n",
      " [0.3935756 ]\n",
      " [0.3935756 ]\n",
      " [0.7500727 ]\n",
      " [0.3935756 ]\n",
      " [0.5020982 ]\n",
      " [0.6670007 ]\n",
      " [0.7585306 ]\n",
      " [0.74851704]\n",
      " [0.3935756 ]\n",
      " [0.3935756 ]\n",
      " [0.81455207]\n",
      " [0.8053458 ]\n",
      " [0.67234844]\n",
      " [0.83527124]\n",
      " [0.8433809 ]\n",
      " [0.954319  ]\n",
      " [0.9256569 ]\n",
      " [0.8900989 ]\n",
      " [0.5455039 ]\n",
      " [0.8302189 ]\n",
      " [0.88304573]\n",
      " [0.92914987]\n",
      " [0.9574841 ]\n",
      " [0.6131942 ]\n",
      " [0.8188741 ]\n",
      " [0.48878118]\n",
      " [0.63735306]\n",
      " [0.3935756 ]\n",
      " [0.3935756 ]\n",
      " [0.8236244 ]\n",
      " [0.78964114]\n",
      " [0.3935756 ]\n",
      " [0.7053977 ]\n",
      " [0.4139486 ]\n",
      " [0.78934515]\n",
      " [0.8299669 ]\n",
      " [0.6172955 ]\n",
      " [0.7747059 ]\n",
      " [0.9128804 ]\n",
      " [0.89387286]\n",
      " [0.92628264]\n",
      " [0.80346155]\n",
      " [0.8107929 ]\n",
      " [0.39433825]\n",
      " [0.7601384 ]\n",
      " [0.3935756 ]\n",
      " [0.3935756 ]\n",
      " [0.8868337 ]\n",
      " [0.61201423]\n",
      " [0.71244   ]\n",
      " [0.688763  ]\n",
      " [0.89633334]\n",
      " [0.72512853]\n",
      " [0.648046  ]\n",
      " [0.69602346]\n",
      " [0.74757504]\n",
      " [0.68464166]\n",
      " [0.8669034 ]\n",
      " [0.47164908]\n",
      " [0.3935756 ]\n",
      " [0.3935756 ]\n",
      " [0.75980544]\n",
      " [0.47622165]\n",
      " [0.6437383 ]\n",
      " [0.3935756 ]\n",
      " [0.86914736]\n",
      " [0.6941714 ]\n",
      " [0.7248781 ]\n",
      " [0.66335976]\n",
      " [0.61416227]\n",
      " [0.3935756 ]\n",
      " [0.4897032 ]\n",
      " [0.80171144]\n",
      " [0.9313103 ]\n",
      " [0.6315652 ]\n",
      " [0.54122293]\n",
      " [0.3935756 ]\n",
      " [0.9233952 ]\n",
      " [0.45619714]\n",
      " [0.8876977 ]\n",
      " [0.4062648 ]\n",
      " [0.93108743]\n",
      " [0.76668954]\n",
      " [0.91847396]\n",
      " [0.6098148 ]\n",
      " [0.41829717]\n",
      " [0.84727955]\n",
      " [0.66656655]\n",
      " [0.87740886]\n",
      " [0.4954314 ]\n",
      " [0.3935756 ]\n",
      " [0.6666197 ]\n",
      " [0.74590147]\n",
      " [0.7243818 ]\n",
      " [0.3935756 ]\n",
      " [0.70002717]\n",
      " [0.92490864]\n",
      " [0.599499  ]\n",
      " [0.5983112 ]\n",
      " [0.8170862 ]\n",
      " [0.86635053]\n",
      " [0.3935756 ]\n",
      " [0.743773  ]\n",
      " [0.3935756 ]\n",
      " [0.60508823]\n",
      " [0.44986668]\n",
      " [0.73472774]\n",
      " [0.69891256]\n",
      " [0.40166205]\n",
      " [0.3935756 ]\n",
      " [0.74538994]\n",
      " [0.83176076]\n",
      " [0.8122175 ]\n",
      " [0.3935756 ]\n",
      " [0.8332233 ]\n",
      " [0.86616385]\n",
      " [0.74796057]\n",
      " [0.39515036]\n",
      " [0.57677466]\n",
      " [0.727727  ]\n",
      " [0.8666116 ]\n",
      " [0.3935756 ]\n",
      " [0.684158  ]\n",
      " [0.6411375 ]\n",
      " [0.70750844]\n",
      " [0.9247772 ]\n",
      " [0.8504634 ]\n",
      " [0.5915473 ]\n",
      " [0.3935756 ]\n",
      " [0.670911  ]\n",
      " [0.8950532 ]\n",
      " [0.8275434 ]\n",
      " [0.5892025 ]\n",
      " [0.9225149 ]\n",
      " [0.8338105 ]\n",
      " [0.86897576]\n",
      " [0.3935756 ]\n",
      " [0.58627844]\n",
      " [0.72995317]\n",
      " [0.92320096]\n",
      " [0.87438726]\n",
      " [0.89430547]\n",
      " [0.75764185]\n",
      " [0.58707464]\n",
      " [0.9275458 ]\n",
      " [0.64255226]\n",
      " [0.3935756 ]\n",
      " [0.6870234 ]\n",
      " [0.83495903]\n",
      " [0.39416692]\n",
      " [0.9001888 ]\n",
      " [0.6645785 ]\n",
      " [0.3935756 ]\n",
      " [0.7415416 ]\n",
      " [0.57982075]\n",
      " [0.49845943]\n",
      " [0.6825149 ]\n",
      " [0.83786833]\n",
      " [0.68272746]\n",
      " [0.74940974]\n",
      " [0.3935756 ]\n",
      " [0.8365937 ]\n",
      " [0.8833379 ]\n",
      " [0.8217919 ]\n",
      " [0.8052304 ]\n",
      " [0.7493414 ]\n",
      " [0.83891183]\n",
      " [0.72994673]\n",
      " [0.89492965]\n",
      " [0.92773604]\n",
      " [0.7295214 ]\n",
      " [0.6352537 ]\n",
      " [0.75845075]\n",
      " [0.62899405]\n",
      " [0.46748555]\n",
      " [0.94334054]\n",
      " [0.6499629 ]\n",
      " [0.5234105 ]\n",
      " [0.7612816 ]\n",
      " [0.61424047]\n",
      " [0.83703804]\n",
      " [0.4464085 ]\n",
      " [0.5374224 ]\n",
      " [0.84114933]\n",
      " [0.807655  ]\n",
      " [0.8372757 ]\n",
      " [0.7308942 ]\n",
      " [0.8078017 ]\n",
      " [0.72222406]\n",
      " [0.3935756 ]\n",
      " [0.8175827 ]\n",
      " [0.70181215]\n",
      " [0.62378246]\n",
      " [0.75777924]\n",
      " [0.85857004]\n",
      " [0.6131626 ]\n",
      " [0.7791658 ]\n",
      " [0.7620759 ]\n",
      " [0.8013358 ]\n",
      " [0.85677403]\n",
      " [0.7179786 ]\n",
      " [0.7098407 ]]\n"
     ]
    }
   ],
   "source": [
    "input_size = 4\n",
    "output_size = 1\n",
    "L2 = 0\n",
    "L_rate = 0.01\n",
    "OUT = []\n",
    "# for i in range(10):\n",
    "INPUT =Input(shape = (Train.shape[1],))\n",
    "x = Dense(input_size, kernel_regularizer = regularizers.l2( L2))(INPUT)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(input_size, kernel_regularizer = regularizers.l2( L2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(input_size, kernel_regularizer = regularizers.l2( L2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(output_size, kernel_regularizer = regularizers.l2( L2))(x)\n",
    "out = Activation('sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=INPUT, outputs=out)\n",
    "model.summary()\n",
    "MY_LR = keras.callbacks.ReduceLROnPlateau(monitor='acc', factor=0.5, patience=40, mode='auto', min_delta=0.0001)\n",
    "MY_ES = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=100,\\\n",
    "                                      verbose=2, mode='auto', restore_best_weights=True)\n",
    "adam=Adam(lr=L_rate, epsilon=1e-8, decay=0)\n",
    "model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
    "model.fit(Train, Label.values, batch_size=256, epochs=1000, verbose=2,\\\n",
    "          class_weight = class_weights,validation_split = 0.2, callbacks = [MY_LR,MY_ES])\n",
    "OUT = model.predict(Test)\n",
    "\n",
    "print(OUT)\n",
    "# print(len(OUT))\n",
    "#OUT = [str(i) for i in OUT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '0', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.55\n",
    "OUT2 = []\n",
    "for i in range(len(OUT)):\n",
    "    if OUT[i][0] > threshold:\n",
    "        OUT2.append('1')\n",
    "    else:\n",
    "        OUT2.append('0')\n",
    "print(OUT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-ab15eca58f52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mANS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Loan_ID'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mTest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Loan_Status'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mOUT2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'Y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'N'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "ANS = pd.DataFrame({'Loan_ID':Test.index, 'Loan_Status':OUT2}).replace({'1':'Y', '0':'N'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ANS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-03b247627918>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mANS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.\\data\\MLP_cos_keras_th_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_L_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m'_L2_'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'_V5.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ANS' is not defined"
     ]
    }
   ],
   "source": [
    "ANS.to_csv('.\\data\\MLP_cos_keras_th_'+str(threshold)+'_L_'+str(input_size)+ '_L2_'+ str(L2) +'_V5.csv',index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Dependents_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Property_Area_Semiurban</th>\n",
       "      <th>Property_Area_Urban</th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>LP001002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165714</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.193917</td>\n",
       "      <td>0.246538</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP001003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056580</td>\n",
       "      <td>0.036192</td>\n",
       "      <td>0.182857</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205476</td>\n",
       "      <td>0.236743</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.752422</td>\n",
       "      <td>0.247578</td>\n",
       "      <td>0.089512</td>\n",
       "      <td>0.031336</td>\n",
       "      <td>0.046474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP001005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094286</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.215111</td>\n",
       "      <td>0.480667</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP001006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>0.056592</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.237469</td>\n",
       "      <td>0.291844</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.522769</td>\n",
       "      <td>0.477231</td>\n",
       "      <td>0.053812</td>\n",
       "      <td>0.052265</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP001008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201429</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.229778</td>\n",
       "      <td>0.240333</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP002978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101429</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239387</td>\n",
       "      <td>0.497241</td>\n",
       "      <td>0.126761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP002979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095254</td>\n",
       "      <td>0.175597</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP002983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099654</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>0.361429</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.297615</td>\n",
       "      <td>0.173484</td>\n",
       "      <td>0.035573</td>\n",
       "      <td>0.971126</td>\n",
       "      <td>0.028874</td>\n",
       "      <td>0.079763</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.010844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP002984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267143</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.241124</td>\n",
       "      <td>0.190162</td>\n",
       "      <td>0.048128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LP002990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.056580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283754</td>\n",
       "      <td>0.314641</td>\n",
       "      <td>0.067669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Gender  Married  Education  Self_Employed  ApplicantIncome  \\\n",
       "Loan_ID                                                                \n",
       "LP001002     0.0      0.0        1.0            0.0         0.072210   \n",
       "LP001003     0.0      1.0        1.0            0.0         0.056580   \n",
       "LP001005     0.0      1.0        1.0            1.0         0.037037   \n",
       "LP001006     0.0      1.0        0.0            0.0         0.031889   \n",
       "LP001008     0.0      0.0        1.0            0.0         0.074074   \n",
       "...          ...      ...        ...            ...              ...   \n",
       "LP002978     1.0      0.0        1.0            0.0         0.035802   \n",
       "LP002979     0.0      1.0        1.0            0.0         0.050691   \n",
       "LP002983     0.0      1.0        1.0            0.0         0.099654   \n",
       "LP002984     0.0      1.0        1.0            0.0         0.093617   \n",
       "LP002990     1.0      0.0        1.0            1.0         0.056580   \n",
       "\n",
       "          CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "Loan_ID                                                                     \n",
       "LP001002           0.000000    0.165714             0.750             1.0   \n",
       "LP001003           0.036192    0.182857             0.750             1.0   \n",
       "LP001005           0.000000    0.094286             0.750             1.0   \n",
       "LP001006           0.056592    0.171429             0.750             1.0   \n",
       "LP001008           0.000000    0.201429             0.750             1.0   \n",
       "...                     ...         ...               ...             ...   \n",
       "LP002978           0.000000    0.101429             0.750             1.0   \n",
       "LP002979           0.000000    0.057143             0.375             1.0   \n",
       "LP002983           0.005760    0.361429             0.750             1.0   \n",
       "LP002984           0.000000    0.267143             0.750             1.0   \n",
       "LP002990           0.000000    0.190000             0.750             0.0   \n",
       "\n",
       "          Dependents_0  ...  Property_Area_Semiurban  Property_Area_Urban  \\\n",
       "Loan_ID                 ...                                                 \n",
       "LP001002           1.0  ...                      0.0                  1.0   \n",
       "LP001003           0.0  ...                      0.0                  0.0   \n",
       "LP001005           1.0  ...                      0.0                  1.0   \n",
       "LP001006           1.0  ...                      0.0                  1.0   \n",
       "LP001008           1.0  ...                      0.0                  1.0   \n",
       "...                ...  ...                      ...                  ...   \n",
       "LP002978           1.0  ...                      0.0                  0.0   \n",
       "LP002979           0.0  ...                      0.0                  0.0   \n",
       "LP002983           0.0  ...                      0.0                  1.0   \n",
       "LP002984           0.0  ...                      0.0                  1.0   \n",
       "LP002990           1.0  ...                      1.0                  0.0   \n",
       "\n",
       "          feature0  feature1  feature2  feature3  feature4  feature5  \\\n",
       "Loan_ID                                                                \n",
       "LP001002  0.193917  0.246538  0.077586  1.000000  0.000000  0.126056   \n",
       "LP001003  0.205476  0.236743  0.070312  0.752422  0.247578  0.089512   \n",
       "LP001005  0.215111  0.480667  0.136364  1.000000  0.000000  0.113636   \n",
       "LP001006  0.237469  0.291844  0.075000  0.522769  0.477231  0.053812   \n",
       "LP001008  0.229778  0.240333  0.063830  1.000000  0.000000  0.106383   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "LP002978  0.239387  0.497241  0.126761  1.000000  0.000000  0.102113   \n",
       "LP002979  0.095254  0.175597  0.112500  1.000000  0.000000  0.256625   \n",
       "LP002983  0.297615  0.173484  0.035573  0.971126  0.028874  0.079763   \n",
       "LP002984  0.241124  0.190162  0.048128  1.000000  0.000000  0.101377   \n",
       "LP002990  0.283754  0.314641  0.067669  1.000000  0.000000  0.086147   \n",
       "\n",
       "          feature6  feature7  \n",
       "Loan_ID                       \n",
       "LP001002  0.000000  0.053935  \n",
       "LP001003  0.031336  0.046474  \n",
       "LP001005  0.000000  0.114219  \n",
       "LP001006  0.052265  0.051282  \n",
       "LP001008  0.000000  0.039825  \n",
       "...            ...       ...  \n",
       "LP002978  0.000000  0.104370  \n",
       "LP002979  0.000000  0.089744  \n",
       "LP002983  0.002523  0.010844  \n",
       "LP002984  0.000000  0.023721  \n",
       "LP002990  0.000000  0.043763  \n",
       "\n",
       "[614 rows x 24 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
